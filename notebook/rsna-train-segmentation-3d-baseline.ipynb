{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Train Code","metadata":{}},{"cell_type":"markdown","source":"## 実行環境のセットアップ\nコードの実行に必要な環境のセットアップ","metadata":{}},{"cell_type":"markdown","source":"### Settings\n機械学習に必要な各種パラメータを設定","metadata":{}},{"cell_type":"code","source":"from pytorch_lightning.callbacks import ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:06:25.606429Z","iopub.execute_input":"2022-09-21T05:06:25.606911Z","iopub.status.idle":"2022-09-21T05:06:29.246104Z","shell.execute_reply.started":"2022-09-21T05:06:25.606856Z","shell.execute_reply":"2022-09-21T05:06:29.244934Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install python-gdcm\n!pip install pylibjpeg pylibjpeg-libjpeg pydicom\n!pip install -qU \"python-gdcm\" pydicom pylibjpeg \"opencv-python-headless\"\n!pip install monai","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:06:29.248272Z","iopub.execute_input":"2022-09-21T05:06:29.249025Z","iopub.status.idle":"2022-09-21T05:07:10.571023Z","shell.execute_reply.started":"2022-09-21T05:06:29.248991Z","shell.execute_reply":"2022-09-21T05:07:10.569690Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: python-gdcm in /opt/conda/lib/python3.7/site-packages (3.0.17.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: pylibjpeg in /opt/conda/lib/python3.7/site-packages (1.4.0)\nRequirement already satisfied: pylibjpeg-libjpeg in /opt/conda/lib/python3.7/site-packages (1.3.1)\nRequirement already satisfied: pydicom in /opt/conda/lib/python3.7/site-packages (2.3.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pylibjpeg) (1.21.6)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: monai in /opt/conda/lib/python3.7/site-packages (1.0.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from monai) (1.21.6)\nRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from monai) (1.11.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->monai) (4.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# Common Settings\n\n# 学習者氏名\nTRAINER = \"yamaday\"\n# エポック数\nNUM_EPOCH = 10\nCLASS_NUM = 13\n# GCP のプロジェクトID\nGCP_PROJECT_ID = \"ai-facade\"\n# GCS のバケット名\nGCS_BUCKET_NAME = \"ai-facade-competitions\"\n\n# コンペのプロジェクトID\nCEREBRUM_PROJECT_ID = \"202208_cervical_spine_fracture_detection\"","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:10.573371Z","iopub.execute_input":"2022-09-21T05:07:10.573834Z","iopub.status.idle":"2022-09-21T05:07:10.582465Z","shell.execute_reply.started":"2022-09-21T05:07:10.573784Z","shell.execute_reply":"2022-09-21T05:07:10.581453Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# DEV RUN\n\n# Trainer の開発モード指定\n#   - False: Trainer を本番モードで運用\n#   - True : Trainer を開発モードで運用（1ステップで終了）\n#   - (int): Trainer を開発モードで運用（任意のステップ数を実行して終了）\nFAST_DEV_RUN = False\n\n# 開発用のデータ削減\n#   - False: データ数を削減しない\n#   - (int): 指定した数までデータ数を削減\nDEV_DATA_SIZE = False\n\n# for debug: (https://qiita.com/makopo/items/170c939c79dcc5c89e12)\n# from IPython.core.debugger import Pdb; Pdb().set_trace()","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:10.586034Z","iopub.execute_input":"2022-09-21T05:07:10.586479Z","iopub.status.idle":"2022-09-21T05:07:10.593404Z","shell.execute_reply.started":"2022-09-21T05:07:10.586444Z","shell.execute_reply":"2022-09-21T05:07:10.592319Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Training Settings\n\nMODEL_OPTION = {\n    \"model\": {\n        \"name\": \"baseline/segmentation/Unet\",\n        \"params\": {\n            \"base.model\": \"Unet\",\n            \"fc.model\": \"\"\n        }\n    },\n    \"optimizer\": {\n        \"name\": \"AdamW\",\n        \"params\": {\n            \"model.lr\": 2e-3,\n            \"weight_decay\": 1e-6,\n            \"eps\": 1e-6,\n        }\n    },\n    \"scheduler\": {\n        \"name\": \"transformer_cosine\",\n        \"params\": {\n            \"num_warmup_steps\": 0,\n            \"num_cycles\": 0.5\n        }\n    },\n    \"criterion\": {\n        \"name\": [\"BCEWithLogitsLoss\"],\n        \"params\": {\n            \"reduction\": \"none\"\n        }\n    }\n}\n\nDATASET_OPTION = {\n    \"source\": \"original\",\n    \"train_test_split\": [],\n    \"train_valid_split\": [],\n}\n\nTRAINING_OPTION = {\n    \"batch_size\": 4,\n    \"custom\": {\n        \"dev_run\": FAST_DEV_RUN,\n        \"dev_data_size\": DEV_DATA_SIZE,\n        \"n_split\": 5,\n        \"target_fold\": [0],\n#         \"target_fold\": list(range(0, 5)),\n        \"fold_method\": \"StratifiedGroupKFold\",\n        \"early_stopping\": False,\n        \"save_each_model\": False,\n        \"save_best_loss_model\": True,\n        \"save_best_score_model\": True,\n        \"auto_scale_batch_size\": False,\n        \"auto_lr_find\": True,\n        \"image_size\": 224,\n        \"transforms\": True,\n    }\n}\n\nENVIRONMENT_OPTION = {\n    \"random_seed\": 42,\n    \"custom\": {\n        \"apex\": False\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:10.595251Z","iopub.execute_input":"2022-09-21T05:07:10.595659Z","iopub.status.idle":"2022-09-21T05:07:10.606294Z","shell.execute_reply.started":"2022-09-21T05:07:10.595625Z","shell.execute_reply":"2022-09-21T05:07:10.605034Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Setup\nライブラリのインポート、グローバル変数の定義","metadata":{}},{"cell_type":"code","source":"!pip uninstall -y pytorch-lightning\n!pip install pytorch-lightning==1.6.4\n!pip install segmentation-models-pytorch==0.2.1\n\nimport os\nimport sys\nimport gc\nimport itertools\nimport platform\nimport datetime\nimport logging\nimport ast\nimport zipfile\nimport warnings\nimport pandas as pd\nimport numpy as np\nfrom copy import deepcopy\nfrom pytz import timezone, utc\nfrom glob import glob\nfrom joblib import Parallel, delayed\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\nimport cv2\nimport random\nfrom tqdm import tqdm\ntqdm.pandas()\nimport pydicom\nfrom matplotlib import pyplot as plt\nimport re\n\n# sklearn\nfrom sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold, GroupKFold\nfrom sklearn.metrics import f1_score\nfrom scipy.spatial.distance import directed_hausdorff\n\n# segmentation-models-pytorch\nimport segmentation_models_pytorch as smp\nimport monai\nfrom monai.data import CSVDataset\nfrom monai.data import DataLoader\nimport nibabel as nib\n\n# torch\nimport torch\nimport torch.nn as nn\nfrom torch.optim import AdamW\nfrom torch.utils.data import Dataset, DataLoader\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom sklearn import preprocessing\n\nimport albumentations as A\nimport torch.nn.functional as F\n\nimport segmentation_models_pytorch as smp\n\nfrom transformers import (\n    get_linear_schedule_with_warmup,\n    get_cosine_schedule_with_warmup,\n    get_cosine_with_hard_restarts_schedule_with_warmup\n)\n\n# pytorch-lightning\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import Callback, ModelCheckpoint\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\n\n# google cloud plotform\nfrom google.cloud import storage\n\nwarnings.simplefilter('ignore')\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nprint(\"-\" * 20)\nprint(f\"pytorch_lightning version: {pl.__version__}\")\nprint(f\"smp version: {pl.__version__}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:10.607966Z","iopub.execute_input":"2022-09-21T05:07:10.608383Z","iopub.status.idle":"2022-09-21T05:07:43.302430Z","shell.execute_reply.started":"2022-09-21T05:07:10.608350Z","shell.execute_reply":"2022-09-21T05:07:43.301305Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found existing installation: pytorch-lightning 1.6.4\nUninstalling pytorch-lightning-1.6.4:\n  Successfully uninstalled pytorch-lightning-1.6.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting pytorch-lightning==1.6.4\n  Using cached pytorch_lightning-1.6.4-py3-none-any.whl (585 kB)\nRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.6.4) (4.3.0)\nRequirement already satisfied: pyDeprecate>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.6.4) (0.3.2)\nRequirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.6.4) (2.10.0)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.6.4) (1.21.6)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.6.4) (4.64.0)\nRequirement already satisfied: torchmetrics>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.6.4) (0.9.3)\nRequirement already satisfied: torch>=1.8.* in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.6.4) (1.11.0)\nRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.6.4) (21.3)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.6.4) (6.0)\nRequirement already satisfied: protobuf<=3.20.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.6.4) (3.19.4)\nRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.6.4) (2022.7.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (3.8.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (2.28.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=17.0->pytorch-lightning==1.6.4) (3.0.9)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (0.6.1)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (0.37.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (3.3.7)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (59.8.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (0.4.6)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (1.43.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (2.2.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (1.35.0)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (0.15.0)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (1.8.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (1.15.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (4.8)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (0.2.7)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (1.3.1)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (4.12.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (2022.6.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (2.1.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (2.1.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (21.4.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (1.7.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (1.3.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (0.13.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (6.0.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (4.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (1.2.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (3.8.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (3.2.0)\nInstalling collected packages: pytorch-lightning\nSuccessfully installed pytorch-lightning-1.6.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: segmentation-models-pytorch==0.2.1 in /opt/conda/lib/python3.7/site-packages (0.2.1)\nRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.2.1) (0.12.0)\nRequirement already satisfied: efficientnet-pytorch==0.6.3 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.2.1) (0.6.3)\nRequirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.2.1) (0.7.4)\nRequirement already satisfied: timm==0.4.12 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.2.1) (0.4.12)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.2.1) (1.11.0)\nRequirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.2.1) (2.5.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.2.1) (4.64.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (4.3.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (2.28.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (1.21.6)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (9.1.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch==0.2.1) (1.15.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (2022.6.15)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (3.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m--------------------\npytorch_lightning version: 1.6.4\nsmp version: 1.6.4\n","output_type":"stream"}]},{"cell_type":"code","source":"# task\nTASK = \"semantic-segmentation-3D\"\n\n# idf path\nLOCAL_IDF_PATH = \"models/{model_id}/fold{fold}.idf.json\"\nGCS_IDF_PATH = \"models/{task}/{model_name}/{model_id}{dev_mode}/fold{fold}.idf.json\"\n\n# model path\nLOCAL_MODEL_PATH = \"models/{model_id}/fold-{fold}/generation-{generation}.ckpt\"\nGCS_MODEL_PATH = \"models/{task}/{model_name}/{model_id}{dev_mode}/fold-{fold}/generation-{generation}.ckpt\"\n\nLOCAL_BEST_MODEL_PATH = \"models/{model_id}/fold-{fold}/\"\nGCS_BEST_MODEL_PATH = \"models/{task}/{model_name}/{model_id}{dev_mode}/fold-{fold}/{filename}\"","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:43.304234Z","iopub.execute_input":"2022-09-21T05:07:43.304852Z","iopub.status.idle":"2022-09-21T05:07:43.313696Z","shell.execute_reply.started":"2022-09-21T05:07:43.304809Z","shell.execute_reply":"2022-09-21T05:07:43.311918Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# logger\n\ndef cvt_jst_time(*args):\n    utc_dt = utc.localize(datetime.datetime.utcnow())\n    jst_tz = timezone(\"Asia/Tokyo\")\n    converted = utc_dt.astimezone(jst_tz)\n    return converted.timetuple()\n\n\ndef get_logger():\n    formatter = logging.Formatter(\n        fmt=\"%(asctime)s [%(levelname)s] %(message)s\",\n        datefmt=\"%Y-%m-%d %H:%M:%S\"\n    )\n    formatter.converter = cvt_jst_time\n    \n    logger = logging.getLogger(__name__)\n    logger.setLevel(logging.INFO)\n    \n    handler = logging.StreamHandler(sys.stdout)\n    handler.setLevel(logging.INFO)\n    handler.setFormatter(formatter)\n    \n    logger.addHandler(handler)\n    \n    return logger\n\n\ntry:\n    logger\nexcept NameError:\n    logger = get_logger()","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:43.317392Z","iopub.execute_input":"2022-09-21T05:07:43.318341Z","iopub.status.idle":"2022-09-21T05:07:43.361935Z","shell.execute_reply.started":"2022-09-21T05:07:43.318302Z","shell.execute_reply":"2022-09-21T05:07:43.360892Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Import Cerebrum Connector\n\nCC_PACKAGE_NAME = \"CerebrumConnector.zip\"\n\ndef download_cc_package():\n    logger.info(\"start: download cc package\")\n    gcs_client = storage.Client(project=GCP_PROJECT_ID)\n    bucket = gcs_client.bucket(GCS_BUCKET_NAME)\n    blob = bucket.blob(CC_PACKAGE_NAME)\n    blob.download_to_filename(CC_PACKAGE_NAME)\n    logger.info(\"complete: download cc package\")\n\n\ndef unzip_package():\n    logger.info(\"start: unzip cc package\")\n    with zipfile.ZipFile(CC_PACKAGE_NAME) as zf:\n        zf.extractall()\n    logger.info(\"complete: unzip cc package\")\n\n\nif not os.path.exists(CC_PACKAGE_NAME):\n    download_cc_package()\n    unzip_package()\n\nfrom CerebrumConnector import CerebrumConnector as cc\nfrom CerebrumConnector import GoogleCloudPlatform as cc_gcp","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:43.363821Z","iopub.execute_input":"2022-09-21T05:07:43.364228Z","iopub.status.idle":"2022-09-21T05:07:43.581036Z","shell.execute_reply.started":"2022-09-21T05:07:43.364190Z","shell.execute_reply":"2022-09-21T05:07:43.579838Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Setup Cerebrum Connector\n\ndef get_identification():\n    idf = cc.Identification(\n        cerebrum_project_id=CEREBRUM_PROJECT_ID,\n        trainer=TRAINER,\n        task=TASK,\n        model_name=MODEL_OPTION[\"model\"][\"name\"]\n    )\n    return idf\n\n\ndef get_gcs_connector():\n    gcs_connector = cc_gcp.GCSConnector(\n        gcp_project_name=GCP_PROJECT_ID,\n        bucket_name=GCS_BUCKET_NAME,\n        sub_dir=CEREBRUM_PROJECT_ID\n    )\n    return gcs_connector\n\n\ndef set_options_to_identification(idf):\n    model_option = cc.ModelOption(\n        model=cc.ModelOptionItem(**MODEL_OPTION[\"model\"]),\n        optimizer=cc.ModelOptionItem(**MODEL_OPTION[\"optimizer\"]),\n        scheduler=cc.ModelOptionItem(**MODEL_OPTION[\"scheduler\"]),\n        criterion=cc.ModelOptionItem(**MODEL_OPTION[\"criterion\"])\n    )\n    dataset_option = cc.DatasetOption(**DATASET_OPTION)\n    training_option = cc.TrainingOption(**TRAINING_OPTION)\n    environment_option = cc.EnvironmentOption(**ENVIRONMENT_OPTION)\n    \n    idf.set_options(\n        model_option,\n        dataset_option,\n        training_option,\n        environment_option\n    )\n\n\nidf = get_identification()\nset_options_to_identification(idf)\n\ngcs_connector = get_gcs_connector()","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:43.585537Z","iopub.execute_input":"2022-09-21T05:07:43.585900Z","iopub.status.idle":"2022-09-21T05:07:43.595540Z","shell.execute_reply.started":"2022-09-21T05:07:43.585853Z","shell.execute_reply":"2022-09-21T05:07:43.594334Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# set random seed\n\ndef set_seed(seed = 42):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nset_seed(idf.environment_option.random_seed)","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:43.597959Z","iopub.execute_input":"2022-09-21T05:07:43.598651Z","iopub.status.idle":"2022-09-21T05:07:43.611771Z","shell.execute_reply.started":"2022-09-21T05:07:43.598613Z","shell.execute_reply":"2022-09-21T05:07:43.610918Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing\n機械学習の前処理","metadata":{}},{"cell_type":"code","source":"seg_image_paths = glob(os.path.join('../input/rsna-2022-cervical-spine-fracture-detection/segmentations', \"*\"))\n\nseg_image_uids = pd.DataFrame([f\"{os.path.splitext(os.path.basename(path))[0]}\" for path in seg_image_paths]\n, columns=[\"StudyInstanceUID\"])\n\n_train_df = pd.read_csv('../input/rsna-2022-cervical-spine-fracture-detection/train.csv')\ntrain_bounding_boxes_df = pd.read_csv('../input/rsna-2022-cervical-spine-fracture-detection/train_bounding_boxes.csv')\n_train_df = _train_df.merge(seg_image_uids, on=['StudyInstanceUID'], how='inner')","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:43.615174Z","iopub.execute_input":"2022-09-21T05:07:43.615483Z","iopub.status.idle":"2022-09-21T05:07:43.684672Z","shell.execute_reply.started":"2022-09-21T05:07:43.615454Z","shell.execute_reply":"2022-09-21T05:07:43.683738Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"_train_df","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:43.686364Z","iopub.execute_input":"2022-09-21T05:07:43.686731Z","iopub.status.idle":"2022-09-21T05:07:43.709524Z","shell.execute_reply.started":"2022-09-21T05:07:43.686696Z","shell.execute_reply":"2022-09-21T05:07:43.708567Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"             StudyInstanceUID  patient_overall  C1  C2  C3  C4  C5  C6  C7\n0    1.2.826.0.1.3680043.1363                1   0   0   0   0   1   0   0\n1   1.2.826.0.1.3680043.25704                0   0   0   0   0   0   0   0\n2   1.2.826.0.1.3680043.20647                0   0   0   0   0   0   0   0\n3   1.2.826.0.1.3680043.31077                1   0   0   1   1   1   1   0\n4   1.2.826.0.1.3680043.17960                0   0   0   0   0   0   0   0\n..                        ...              ...  ..  ..  ..  ..  ..  ..  ..\n82  1.2.826.0.1.3680043.32071                1   0   1   0   1   0   1   1\n83  1.2.826.0.1.3680043.30524                1   0   0   0   0   0   1   1\n84  1.2.826.0.1.3680043.28025                0   0   0   0   0   0   0   0\n85  1.2.826.0.1.3680043.21321                1   1   1   1   0   0   0   1\n86  1.2.826.0.1.3680043.26990                1   0   0   0   0   1   1   1\n\n[87 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>StudyInstanceUID</th>\n      <th>patient_overall</th>\n      <th>C1</th>\n      <th>C2</th>\n      <th>C3</th>\n      <th>C4</th>\n      <th>C5</th>\n      <th>C6</th>\n      <th>C7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.2.826.0.1.3680043.1363</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.2.826.0.1.3680043.25704</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.2.826.0.1.3680043.20647</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.2.826.0.1.3680043.31077</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.2.826.0.1.3680043.17960</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>1.2.826.0.1.3680043.32071</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>1.2.826.0.1.3680043.30524</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>1.2.826.0.1.3680043.28025</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>1.2.826.0.1.3680043.21321</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>1.2.826.0.1.3680043.26990</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>87 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def get_path(row):\n    image_paths = glob(os.path.join(f'../input/rsna-2022-cervical-spine-fracture-detection/train_images/{row[\"StudyInstanceUID\"]}', \"*.dcm\"))\n    p = re.compile(r'(\\d+).dcm')\n    image_paths.sort(key=lambda s: int(p.search(s).groups()[0]))\n    \n    if len(image_paths) < idf.training_option.custom['image_size']:\n        ins = [\"\" for i in range(idf.training_option.custom['image_size'] - len(image_paths))]\n        image_paths.extend(ins)\n    row['image_paths'] = image_paths[:idf.training_option.custom['image_size']]\n    row['mask_path'] = f\"../input/rsna-2022-cervical-spine-fracture-detection/segmentations/{row['StudyInstanceUID']}.nii\"\n    row['image_length'] = len(image_paths)\n    return row\n\n_train_df = _train_df.progress_apply(get_path, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:43.711702Z","iopub.execute_input":"2022-09-21T05:07:43.712709Z","iopub.status.idle":"2022-09-21T05:07:45.779016Z","shell.execute_reply.started":"2022-09-21T05:07:43.712668Z","shell.execute_reply":"2022-09-21T05:07:45.778107Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"100%|██████████| 87/87 [00:02<00:00, 42.58it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"_train_df['image_length'].hist()","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:45.783023Z","iopub.execute_input":"2022-09-21T05:07:45.785480Z","iopub.status.idle":"2022-09-21T05:07:46.101761Z","shell.execute_reply.started":"2022-09-21T05:07:45.785436Z","shell.execute_reply":"2022-09-21T05:07:46.100294Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"_train_df[_train_df[\"StudyInstanceUID\"] == \"1.2.826.0.1.3680043.21321\"][\"image_paths\"]","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:46.103090Z","iopub.execute_input":"2022-09-21T05:07:46.103688Z","iopub.status.idle":"2022-09-21T05:07:46.123019Z","shell.execute_reply.started":"2022-09-21T05:07:46.103645Z","shell.execute_reply":"2022-09-21T05:07:46.121745Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"170    [../input/rsna-2022-cervical-spine-fracture-de...\n171    [../input/rsna-2022-cervical-spine-fracture-de...\nName: image_paths, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"mm = preprocessing.MinMaxScaler()\n\ndef read_dcm_file(file_path):\n    image_size = (idf.training_option.custom['image_size'], idf.training_option.custom['image_size'])\n    \n    if not file_path:\n        img = np.zeros(image_size, dtype=np.float32)\n    else:\n        img =  pydicom.read_file(file_path).pixel_array\n        img =  mm.fit_transform(img) * 255.0 \n        img = cv2.resize(img, image_size)\n    img = np.tile(img[...,None], [1, 1, 1]) \n    img = img / 255\n\n    return img\n\ndef read_mask(file_path):\n    image_size = (idf.training_option.custom['image_size'], idf.training_option.custom['image_size'])\n    nii = nib.load(file_path)\n    nii_arrays = nii.get_fdata()  # convert to numpy array\n    \n    mask = nii_arrays[:, :, :idf.training_option.custom['image_size']]\n    if mask.shape[2] < idf.training_option.custom['image_size']:\n        ins = np.zeros((mask.shape[0], mask.shape[1], idf.training_option.custom['image_size'] - mask.shape[2]), dtype=np.float32)\n        mask = np.concatenate([mask, ins], axis=2)\n\n    mask = mask / CLASS_NUM\n    mask = cv2.resize(mask, image_size).transpose(2, 1, 0)\n    mask = np.tile(mask[...,None], [1, 1, 1]) # gray to rgb\n\n    return mask","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:46.124693Z","iopub.execute_input":"2022-09-21T05:07:46.125656Z","iopub.status.idle":"2022-09-21T05:07:46.137906Z","shell.execute_reply.started":"2022-09-21T05:07:46.125609Z","shell.execute_reply":"2022-09-21T05:07:46.136938Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"p = read_dcm_file(\"../input/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.20928/80.dcm\")","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:46.139523Z","iopub.execute_input":"2022-09-21T05:07:46.139942Z","iopub.status.idle":"2022-09-21T05:07:46.193174Z","shell.execute_reply.started":"2022-09-21T05:07:46.139906Z","shell.execute_reply":"2022-09-21T05:07:46.192174Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"imgs_ex = []\nfor img_path in _train_df.iloc[0]['image_paths']:\n    imgs_ex.append(read_dcm_file(img_path))\n\nmask_path = _train_df.iloc[0]['mask_path']\nmasks = read_mask(mask_path)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-09-21T05:07:46.194495Z","iopub.execute_input":"2022-09-21T05:07:46.194817Z","iopub.status.idle":"2022-09-21T05:07:50.487471Z","shell.execute_reply.started":"2022-09-21T05:07:46.194784Z","shell.execute_reply":"2022-09-21T05:07:50.486179Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"imgs_ex[1].shape","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:50.489196Z","iopub.execute_input":"2022-09-21T05:07:50.489555Z","iopub.status.idle":"2022-09-21T05:07:50.499062Z","shell.execute_reply.started":"2022-09-21T05:07:50.489517Z","shell.execute_reply":"2022-09-21T05:07:50.497935Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(224, 224, 1)"},"metadata":{}}]},{"cell_type":"code","source":"masks.shape","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:50.500435Z","iopub.execute_input":"2022-09-21T05:07:50.501206Z","iopub.status.idle":"2022-09-21T05:07:50.509838Z","shell.execute_reply.started":"2022-09-21T05:07:50.501167Z","shell.execute_reply":"2022-09-21T05:07:50.508724Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(224, 224, 224, 1)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training\n機械学習を実行","metadata":{}},{"cell_type":"markdown","source":"### データを分割","metadata":{}},{"cell_type":"code","source":"# split dataset (k-fold)\n\ndef k_fold(idf, raw_df):\n    df = raw_df.copy()\n    n_splits = idf.training_option.custom[\"n_split\"]\n    if idf.training_option.custom[\"fold_method\"] == \"StratifiedGroupKFold\":\n        skf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True)\n        for fold, (_, val_idx) in enumerate(skf.split(X=df, y=df['patient_overall'], groups=df['StudyInstanceUID'])):\n            df.loc[val_idx, 'fold'] = int(fold)\n    df['fold'] = df['fold'].astype(np.uint8)\n    return df\n\n# 開発用のデータ削減\nif DEV_DATA_SIZE:\n    logger.info(f\"DEV_MODE: data size: {len(_train_df)} -> {DEV_DATA_SIZE}\")\n    _train_df = _train_df[:DEV_DATA_SIZE]\n    \n_train_df = k_fold(idf, _train_df)\nlogger.info(\"split dataset. size: {}\".format(_train_df.groupby(\"fold\").size().to_dict()))\n\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:50.511162Z","iopub.execute_input":"2022-09-21T05:07:50.512249Z","iopub.status.idle":"2022-09-21T05:07:50.874054Z","shell.execute_reply.started":"2022-09-21T05:07:50.512208Z","shell.execute_reply":"2022-09-21T05:07:50.872903Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"2022-09-21 14:07:50 [INFO] split dataset. size: {0: 36, 1: 36, 2: 34, 3: 34, 4: 34}\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"### Dataset","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\nmm = preprocessing.MinMaxScaler()\n\nclass CustomDataset(Dataset):\n    def __init__(self, idf, df, transforms=None):\n        self.idf = idf\n        self.df = df\n        self.img_paths  = df['image_paths'].tolist()\n        self.mask_paths  = df['mask_path'].tolist()\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_paths  = self.img_paths[index]\n        imgs = []\n        for img_path in img_paths:\n            imgs.append(self._read_dcm_file(img_path))\n        \n        mask_path = self.mask_paths[index]\n        masks = self._read_mask(mask_path)\n        \n        if self.transforms is not None:\n            imgs = np.array(imgs, dtype=np.float32)\n            aug = self.transforms(image=imgs, mask=masks)\n            imgs = aug['image']\n            masks = aug['mask']\n        \n        imgs = np.array(imgs, dtype=np.float32)\n        imgs = imgs.transpose(3, 1, 2, 0)\n        masks = masks.transpose(3, 1, 2, 0)\n\n        return torch.tensor(imgs, dtype=torch.float), torch.tensor(masks, dtype=torch.float)\n    \n    def _read_dcm_file(self, file_path):\n        image_size = (self.idf.training_option.custom['image_size'], self.idf.training_option.custom['image_size'])\n        if not file_path:\n            img = np.zeros(image_size, dtype=np.float16)\n        else:\n            img =  pydicom.read_file(file_path).pixel_array\n            img =  mm.fit_transform(img) * 255.0 \n            img = cv2.resize(img, image_size)\n        img = np.tile(img[...,None], [1, 1, 1]) \n        img = img / 255\n\n        return img\n\n    def _read_mask(self, file_path):\n        image_size = (self.idf.training_option.custom['image_size'], self.idf.training_option.custom['image_size'])\n        nii = nib.load(file_path)\n        nii_arrays = nii.get_fdata()  # convert to numpy array\n        mask = nii_arrays[:, :, :self.idf.training_option.custom['image_size']]\n        if mask.shape[2] < idf.training_option.custom['image_size']:\n            ins = np.zeros((mask.shape[0], mask.shape[1], self.idf.training_option.custom['image_size'] - mask.shape[2]), dtype=np.float16)\n            mask = np.concatenate([mask, ins], axis=2)\n    \n        mask = mask / CLASS_NUM\n        mask = cv2.resize(mask, image_size).transpose(2, 1, 0)\n        mask = np.tile(mask[...,None], [1, 1, 1]) # gray to rgb\n\n        return mask","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:50.876026Z","iopub.execute_input":"2022-09-21T05:07:50.876485Z","iopub.status.idle":"2022-09-21T05:07:50.893919Z","shell.execute_reply.started":"2022-09-21T05:07:50.876439Z","shell.execute_reply":"2022-09-21T05:07:50.892940Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### DataModule","metadata":{}},{"cell_type":"code","source":"class CustomDataModule(pl.LightningDataModule):\n    def __init__(self, idf, train_df, valid_df, transforms=None):\n        super().__init__()\n        \n        self.idf = idf\n        self.train_df = train_df\n        self.valid_df = valid_df\n        self.train_transforms = transforms['train'] if transforms != None else None\n        self.valid_transforms = transforms['valid'] if transforms != None else None   \n        \n    def train_dataloader(self):\n        dataset = CustomDataset(self.idf, self.train_df, self.train_transforms)\n        data_loader = DataLoader(\n            dataset,\n            batch_size=self.idf.training_option.batch_size,\n            shuffle=True,\n            num_workers=os.cpu_count(),\n            pin_memory=True,\n            drop_last=True\n        )\n        return data_loader\n    \n    def val_dataloader(self):\n        dataset = CustomDataset(self.idf, self.valid_df, self.valid_transforms)\n        data_loader = DataLoader(\n            dataset,\n            batch_size=self.idf.training_option.batch_size,\n            shuffle=False,\n            num_workers=os.cpu_count(),\n            pin_memory=True,\n            drop_last=True\n        )\n        return data_loader","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:50.895676Z","iopub.execute_input":"2022-09-21T05:07:50.896178Z","iopub.status.idle":"2022-09-21T05:07:50.907199Z","shell.execute_reply.started":"2022-09-21T05:07:50.896135Z","shell.execute_reply":"2022-09-21T05:07:50.906106Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### transforms","metadata":{}},{"cell_type":"code","source":"data_transforms =  {\n    \"train\": A.Compose([\n        A.HorizontalFlip(),\n        A.VerticalFlip(),\n        A.OneOf([\n            A.RandomContrast(),\n            A.RandomGamma(),\n            A.RandomBrightness(),\n        ], p=0.5),\n    ], p=1.0),\n    \"valid\": None} if idf.training_option.custom[\"transforms\"] else None","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:50.908992Z","iopub.execute_input":"2022-09-21T05:07:50.909371Z","iopub.status.idle":"2022-09-21T05:07:50.922915Z","shell.execute_reply.started":"2022-09-21T05:07:50.909336Z","shell.execute_reply":"2022-09-21T05:07:50.921839Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### Scoring functions","metadata":{}},{"cell_type":"code","source":"# Scoring functions\nclass ScoringFn():\n    @classmethod\n    def scoring(cls, pred, label):\n        \"\"\" スコアリング \"\"\"\n        score = F.binary_cross_entropy_with_logits(pred, label)\n        return score\n","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:50.924386Z","iopub.execute_input":"2022-09-21T05:07:50.924905Z","iopub.status.idle":"2022-09-21T05:07:50.932996Z","shell.execute_reply.started":"2022-09-21T05:07:50.924851Z","shell.execute_reply":"2022-09-21T05:07:50.932006Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### Optimizer & Scheduler","metadata":{}},{"cell_type":"code","source":"# Optimizer Utilities\n\nclass OptimizerUtils():\n    @staticmethod\n    def get_optimizer(idf, model, lr):\n        \"\"\" optimizer を取得 \"\"\"\n        optimizer_name = idf.model_option.optimizer.name\n        optimizer_params = idf.model_option.optimizer.params\n\n        if optimizer_name == \"AdamW\":\n            return AdamW(model.parameters(), \n                         lr=lr,\n                         eps=optimizer_params[\"eps\"], \n                         weight_decay=optimizer_params[\"weight_decay\"])\n        else:\n            raise Exception(f\"optimizer: {optimizer_name} is not supported.\")\n    \n    @staticmethod\n    def get_scheduler(idf, optimizer, num_training_steps, train_dl_size):\n        \"\"\" scheduler を取得 \"\"\"\n        scheduler_name = idf.model_option.scheduler.name\n        scheduler_params = idf.model_option.scheduler.params\n        \n        if scheduler_params[\"num_warmup_steps\"] == \"first_epoch\":\n            scheduler_params[\"num_warmup_steps\"] = train_dl_size\n        \n        if scheduler_name == \"transformer_cosine\":\n            return get_cosine_schedule_with_warmup(\n                optimizer,\n                num_training_steps=num_training_steps,\n                **scheduler_params\n            )\n        \n        elif scheduler_name == \"transformer_cosine_with_hard_restarts\":\n            return get_cosine_with_hard_restarts_schedule_with_warmup(\n                optimizer,\n                num_training_steps=num_training_steps,\n                **scheduler_params\n            )\n        \n        elif scheduler_name == \"transformer_linear\":\n            return get_linear_schedule_with_warmup(\n                optimizer,\n                num_training_steps=num_training_steps,\n                **scheduler_params\n            )\n\n        else:\n            raise Exception(f\"scheduler: {scheduler_name} is not supported.\") ","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:50.934990Z","iopub.execute_input":"2022-09-21T05:07:50.935367Z","iopub.status.idle":"2022-09-21T05:07:50.946531Z","shell.execute_reply.started":"2022-09-21T05:07:50.935331Z","shell.execute_reply":"2022-09-21T05:07:50.945401Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Criterion","metadata":{}},{"cell_type":"code","source":"# Criterion Utilities\n\nclass CriterionUtils():\n    @staticmethod\n    def get_criterion(criterion_name, criterion_params):\n        \"\"\" criterion を取得 \"\"\"\n        if criterion_name == \"BCEWithLogitsLoss\":\n            return nn.BCEWithLogitsLoss(**criterion_params)\n        else:\n            raise Exception(f\"criterion: {criterion_name} is not supported.\") ","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:50.952802Z","iopub.execute_input":"2022-09-21T05:07:50.953138Z","iopub.status.idle":"2022-09-21T05:07:50.960021Z","shell.execute_reply.started":"2022-09-21T05:07:50.953112Z","shell.execute_reply":"2022-09-21T05:07:50.958810Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"# Inner Model\n\nclass InnerModel(nn.Module):\n    def __init__(self, idf):\n        super().__init__()\n        self.idf = idf\n        # model config\n        base_model_name = idf.model_option.model.params[\"base.model\"]\n        self.model = self.__build_base_model(base_model_name)\n        self.fc = nn.Sequential(nn.ReLU())\n        \n    def forward(self, inputs):\n        output = self.model(inputs)\n        output = self.fc(output)\n        \n        return output\n    \n    def __build_base_model(self, base_model_name):\n        if base_model_name == \"Unet\":\n            return monai.networks.nets.UNet(\n                spatial_dims=3,\n                in_channels=1,\n                out_channels=1,\n                channels=(16, 32, 64, 128, 256),\n                strides=(2, 2, 2, 2),\n                num_res_units=2,\n            )\n            raise Exception(f\"model: {fc_model_name} is not supported.\")\n","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:50.962024Z","iopub.execute_input":"2022-09-21T05:07:50.962390Z","iopub.status.idle":"2022-09-21T05:07:50.974044Z","shell.execute_reply.started":"2022-09-21T05:07:50.962353Z","shell.execute_reply":"2022-09-21T05:07:50.972978Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# LightningModule\n\nclass CustomModel(pl.LightningModule):\n    def __init__(self, idf, valid_df, train_dl_size, epoch_size):\n        super().__init__()\n        \n        self.idf = idf\n        # スコア算出に使用する valid データセット\n        self.valid_df = valid_df\n        self.lr = self.idf.model_option.optimizer.params[\"model.lr\"]\n        \n        # scheduler の num_training_steps 引数\n        self.train_dl_size = train_dl_size\n        self.epoch_size = epoch_size\n        self.num_training_steps = train_dl_size * epoch_size\n        \n        # model\n        self.model = InnerModel(self.idf)\n        \n    def forward(self, inputs):\n        \"\"\" 予測を実行 \"\"\"\n        output = self.model(inputs)\n\n        return output\n    \n    def configure_optimizers(self):\n        \"\"\" optimizer, scheduler を取得 \"\"\"\n        optimizer = OptimizerUtils.get_optimizer(self.idf, self.model, self.lr)\n        scheduler = {\n            \"scheduler\": OptimizerUtils.get_scheduler(\n                self.idf,\n                optimizer,\n                self.num_training_steps,\n                self.train_dl_size\n            ),\n            \"interval\": \"step\"\n        }\n        return [optimizer], [scheduler]\n    \n    def training_step(self, batch, batch_idx):\n        \"\"\" Train 処理 \"\"\"\n        loss, _ = self.__common_step(batch, mode=\"train\")\n        return {\"loss\": loss}\n    \n    def validation_step(self, batch, batch_idx):\n        \"\"\" Valid 処理\"\"\"\n        loss, preds = self.__common_step(batch, mode=\"valid\")\n        return {\"loss\": loss, \"pred\": preds, \"label\": batch[1]}\n    \n    def __common_step(self, batch, mode):\n        \"\"\" Train と Valid に共通の処理\"\"\"\n        inputs, labels, = batch\n        y_preds = self.forward(inputs)\n\n        flatten_y_preds = y_preds.view(-1, 1)\n        flatten_labels = labels.view(-1, 1)\n\n        # criterion\n        criterion_names = self.idf.model_option.criterion.name\n        criterion_params = self.idf.model_option.criterion.params\n        losses = []\n        for criterion_name in criterion_names:  \n            criterion = CriterionUtils.get_criterion(criterion_name, criterion_params)\n            loss = criterion(flatten_y_preds, flatten_labels)\n            loss = torch.masked_select(loss, flatten_labels != -1).mean()\n            losses.append(loss)\n        loss = sum(losses) / len(losses)\n                    \n        if torch.isnan(loss):\n            loss = torch.tensor(1.0)\n\n        return loss, y_preds\n    \n    def training_epoch_end(self, outputs):\n        \"\"\" Train の最終処理 \"\"\"\n        # Training ループの最後に呼ばれる\n        avg_losses = self.__common_epoch_end(outputs)\n        self.log(\"train_loss\", avg_losses)\n    \n    def validation_epoch_end(self, outputs):\n        \"\"\" Valid の最終処理 \"\"\"\n        # Valid ループの最後に呼ばれる\n        avg_losses = self.__common_epoch_end(outputs)\n\n        self.log(\"valid_loss\", avg_losses)\n        score = self.__scoring(outputs)\n        self.log(\"score\", score)\n        \n    def __common_epoch_end(self, outputs):\n        \"\"\" Train と Valid に共通の最終処理\"\"\"\n        losses = []\n        for output in outputs:\n            loss = output[\"loss\"].to(\"cpu\").detach().numpy().copy()\n            losses.append(loss)\n        losses = np.array(losses)\n        return np.average(losses)\n    \n    def __scoring(self, outputs):\n        \"\"\" スコア算出 \"\"\"\n        scores = []\n        for output in outputs:\n            pred = output[\"pred\"].to(\"cpu\").detach()\n            label = output[\"label\"].to(\"cpu\").detach()\n            val_score = ScoringFn.scoring(pred, label)\n            scores.append(val_score)\n\n        return np.mean(scores, axis=0)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:09:16.042578Z","iopub.execute_input":"2022-09-21T05:09:16.043186Z","iopub.status.idle":"2022-09-21T05:09:16.074018Z","shell.execute_reply.started":"2022-09-21T05:09:16.043137Z","shell.execute_reply":"2022-09-21T05:09:16.072838Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"### Callback","metadata":{}},{"cell_type":"code","source":"# Custom Callback for Cerebrum\n\nclass CustomCallback(Callback):\n    def __init__(self, idf, fold):\n        self.idf = deepcopy(idf)\n        self.fold = fold\n        self.save_each_model = self.idf.training_option.custom[\"save_each_model\"]\n        \n        self.timer = cc.Timer()\n        \n        # Identification に現在の学習環境を登録\n        self.env_id = len(self.idf.environments)\n        env = cc.Environment(\n            env_id=self.env_id,\n            trainer=self.idf.trainer,\n            platform_name=platform.platform(),\n            cpu_count=os.cpu_count(),\n            gpu_name=torch.cuda.get_device_name(),\n            gpu_count=torch.cuda.device_count()\n        )\n        self.idf.add_environment(env)\n    \n    def on_train_epoch_start(self, trainer, pl_model):\n        \"\"\" train epoch 開始時の処理 \"\"\"\n        self.timer.reset()\n        self.timer.start()\n        \n        generation = self.idf.model_generation\n        current_epoch = trainer.current_epoch\n        logger.info(\n            f\"start epoch-{current_epoch}: \"\n            f\"generation: {generation} -> {generation + 1}\"\n        )\n    \n    def on_train_epoch_end(self, trainer, pl_model):\n        \"\"\" train epoch 終了時の処理 \"\"\"\n        self.timer.stop()\n        elapsed_time = self.timer.get_elapsed_time(format=True)\n        \n        train_loss = trainer.callback_metrics[\"train_loss\"]\n        train_loss = train_loss.to(\"cpu\").detach().numpy().copy()\n        \n        valid_loss = trainer.callback_metrics[\"valid_loss\"]\n        valid_loss = valid_loss.to(\"cpu\").detach().numpy().copy()\n        \n        score = trainer.callback_metrics[\"score\"]\n        score = score.to(\"cpu\").detach().numpy().copy()\n        \n        self.__add_history(train_loss, valid_loss, score)\n        \n        self.__save_idf()\n        \n        if self.save_each_model:\n            self.__save_model(trainer)\n            \n    \n    def __add_history(self, train_loss, valid_loss, score):\n        \"\"\" identification に学習履歴を記録 \"\"\"\n        generation = self.idf.model_generation + 1\n        history_item = cc.Generation(\n            generation=generation,\n            env_id=self.env_id,\n            train_loss=float(train_loss),\n            valid_loss=float(valid_loss),\n            score=float(score),\n            elapsed_sec=self.timer.get_elapsed_time(),\n            recorded_at=self.__get_current_timestamp()\n        )\n        self.idf.add_history(history_item)\n        logger.info(\n            \"save history (generation={}): \"\n            \"train_loss: {:.5f}, valid_loss: {:.5f}, score: {:.5f}\".format(\n                generation, train_loss, valid_loss, score\n            )\n        )\n    \n    def __save_idf(self):\n        \"\"\" identification を GCS に保存 \"\"\"\n        local_path = LOCAL_IDF_PATH.format(\n            model_id=self.idf.model_id, fold=self.fold)\n        self.idf.save(local_path)\n        logger.info(f\"save identification to local: {local_path}\")\n        \n        gcs_path = GCS_IDF_PATH.format(\n            task=TASK,\n            model_name=self.idf.model_name,\n            model_id=self.idf.model_id,\n            dev_mode=\"(Dev)\" if FAST_DEV_RUN or DEV_DATA_SIZE else \"\",\n            fold=self.fold\n        )\n        gcs_connector.upload_to_gcs(local_path, gcs_path)\n        logger.info(f\"save identification to GCS: {gcs_path}\")\n    \n    def __save_model(self, trainer):\n        \"\"\" model を GCS に保存 \"\"\"\n        local_path = LOCAL_MODEL_PATH.format(\n            model_id=self.idf.model_id,\n            fold=self.fold,\n            generation=self.idf.model_generation\n        )\n        trainer.save_checkpoint(local_path)\n        logger.info(f\"save model to local: {local_path}\")\n        \n        gcs_path = GCS_MODEL_PATH.format(\n            task=TASK,\n            model_name=self.idf.model_name,\n            model_id=self.idf.model_id,\n            dev_mode=\"(Dev)\" if FAST_DEV_RUN or DEV_DATA_SIZE else \"\",\n            fold=self.fold,\n            generation=self.idf.model_generation\n        )\n        gcs_connector.upload_to_gcs(local_path, gcs_path)\n        logger.info(f\"save model to GCS: {gcs_path}\")\n    \n    def __get_current_timestamp(self):\n        \"\"\" identification に記録する現在時刻を取得 \"\"\"\n        datetime_now = datetime.datetime.now(\n            datetime.timezone(datetime.timedelta(hours=9))\n        )\n        return datetime_now.strftime(\"%Y%m%d-%H%M%S\")","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:50.999359Z","iopub.execute_input":"2022-09-21T05:07:50.999794Z","iopub.status.idle":"2022-09-21T05:07:51.021130Z","shell.execute_reply.started":"2022-09-21T05:07:50.999757Z","shell.execute_reply":"2022-09-21T05:07:51.020081Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Callbacks\n\nclass Callbacks():\n    def __init__(self, idf, fold):\n        self.idf = idf\n        self.fold = fold\n        \n        self.base_callback = self._get_base_callback()\n        self.early_stopping = self._get_early_stopping()\n        self.min_loss_checkpoint = self._get_min_loss_checkpoint()\n        self.max_score_checkpoint = self._get_max_score_checkpoint()\n        \n        _callbacks = [\n            self.base_callback,\n            self.early_stopping,\n            self.min_loss_checkpoint,\n            self.max_score_checkpoint\n        ]\n        self.callbacks = [c for c in _callbacks if c is not None]\n        \n    @property\n    def has_min_loss_checkpoint(self):\n        return self.min_loss_checkpoint is not None\n    \n    @property\n    def has_max_score_checkpoint(self):\n        return self.max_score_checkpoint is not None\n        \n    @property\n    def min_loss_ckpt_path(self):\n        if self.min_loss_checkpoint is None:\n            return None\n        return self.min_loss_checkpoint.best_model_path\n    \n    @property\n    def max_score_ckpt_path(self):\n        if self.max_score_checkpoint is None:\n            return None\n        return self.max_score_checkpoint.best_model_path\n    \n    def _get_base_callback(self):\n        base_callback = CustomCallback(self.idf, self.fold)\n        return base_callback\n    \n    def _get_early_stopping(self):\n        if not self.idf.training_option.custom[\"early_stopping\"]:\n            return None\n        \n        early_stopping = EarlyStopping(monitor=\"valid_loss\")\n        return early_stopping\n    \n    def _get_min_loss_checkpoint(self):\n        if not self.idf.training_option.custom[\"save_best_loss_model\"]:\n            return None\n        \n        dirpath = LOCAL_BEST_MODEL_PATH.format(model_id=self.idf.model_id, fold=self.fold)\n        min_loss_checkpoint = ModelCheckpoint(\n            dirpath=dirpath,\n            filename=\"min-loss_{epoch}\",\n            monitor=\"valid_loss\",\n            save_top_k=1,\n            mode=\"min\",\n            save_weights_only=True\n        )\n        return min_loss_checkpoint\n    \n    def _get_max_score_checkpoint(self):\n        if not self.idf.training_option.custom[\"save_best_score_model\"]:\n            return None\n        \n        dirpath = LOCAL_BEST_MODEL_PATH.format(model_id=self.idf.model_id, fold=self.fold)\n        max_score_checkpoint = ModelCheckpoint(\n            dirpath=dirpath,\n            filename=\"max-score_{epoch}\",\n            monitor=\"score\",\n            save_top_k=1,\n            mode=\"max\",\n            save_weights_only=True\n        )\n        return max_score_checkpoint","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:51.022857Z","iopub.execute_input":"2022-09-21T05:07:51.023488Z","iopub.status.idle":"2022-09-21T05:07:51.037997Z","shell.execute_reply.started":"2022-09-21T05:07:51.023454Z","shell.execute_reply":"2022-09-21T05:07:51.037015Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"### Model Saving Utils","metadata":{}},{"cell_type":"code","source":"# Model Saving Utilities\n\nclass ModelSavingUtils():\n    @staticmethod\n    def upload_base_model_to_gcs(idf, fold, local_path):\n        \"\"\" best-model を GCS にアップロード \"\"\"\n        ckpt_name = os.path.basename(local_path)\n        gcs_path = GCS_BEST_MODEL_PATH.format(\n            task=TASK,\n            model_name=idf.model_name,\n            model_id=idf.model_id,\n            dev_mode=\"(Dev)\" if FAST_DEV_RUN or DEV_DATA_SIZE else \"\",\n            fold=fold,\n            filename=ckpt_name\n        )\n        gcs_connector.upload_to_gcs(local_path, gcs_path)\n        logger.info(f\"save model to GCS: {gcs_path}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:07:51.040800Z","iopub.execute_input":"2022-09-21T05:07:51.041766Z","iopub.status.idle":"2022-09-21T05:07:51.052561Z","shell.execute_reply.started":"2022-09-21T05:07:51.041734Z","shell.execute_reply":"2022-09-21T05:07:51.051571Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"### Train","metadata":{}},{"cell_type":"code","source":"# Machine Learning\n\nlogger.info(\"start training: model_id={}, n_fold={}, target_fold={}, early_stopping={}\".format(\n    idf.model_id,\n    idf.training_option.custom[\"n_split\"],\n    idf.training_option.custom[\"target_fold\"],\n    idf.training_option.custom[\"early_stopping\"]\n))\n\nfor fold in idf.training_option.custom[\"target_fold\"]:\n    logger.info(f\"fold-{fold} start\")\n    train_df = _train_df[_train_df[\"fold\"] != fold]\n    valid_df = _train_df[_train_df[\"fold\"] == fold]\n    \n    datamodule = CustomDataModule(idf, train_df, valid_df, data_transforms)\n    \n    scheduler_steps = len(datamodule.train_dataloader()) * NUM_EPOCH\n    model = CustomModel(\n        idf,\n        valid_df,\n        len(datamodule.train_dataloader()),\n        NUM_EPOCH\n    )\n\n    callbacks = Callbacks(idf, fold)\n    \n    trainer_params = {\n        \"max_epochs\": NUM_EPOCH,\n        \"accelerator\": \"gpu\",\n        \"gpus\": 1,\n        \"amp_backend\": \"native\",\n        \"fast_dev_run\": FAST_DEV_RUN,\n        \"callbacks\": callbacks.callbacks,\n        \"auto_scale_batch_size\": idf.training_option.custom[\"auto_scale_batch_size\"],\n        # \"auto_lr_find\": idf.training_option.custom[\"auto_lr_find\"],\n    }\n    \n    if idf.environment_option.custom[\"apex\"]:\n        trainer_params[\"amp_backend\"] = \"apex\"\n        \n    trainer = pl.Trainer(**trainer_params)\n    \n    trainer.tune(model, datamodule=datamodule)\n    logger.info(f\"model_lr: {trainer.model.lr}\")\n    \n    trainer.fit(model, datamodule=datamodule)\n    \n    # upload min-loss model to GCS\n    if callbacks.has_min_loss_checkpoint:\n        local_path = callbacks.min_loss_ckpt_path\n        if local_path:\n            logger.info(f\"min-loss-model: {local_path}\")\n            ModelSavingUtils.upload_base_model_to_gcs(idf, fold, local_path)\n    \n    # upload max-score model to GCS\n    if callbacks.has_max_score_checkpoint:\n        local_path = callbacks.max_score_ckpt_path\n        if local_path:\n            logger.info(f\"max-score-model: {local_path}\")\n            ModelSavingUtils.upload_base_model_to_gcs(idf, fold, local_path)\n    \n    del datamodule, model, trainer\n    gc.collect()\n    logger.info(f\"fold-{fold} end\")\n\nlogger.info(\"end training\")","metadata":{"execution":{"iopub.status.busy":"2022-09-21T05:09:19.892538Z","iopub.execute_input":"2022-09-21T05:09:19.893073Z","iopub.status.idle":"2022-09-21T06:32:32.891343Z","shell.execute_reply.started":"2022-09-21T05:09:19.893028Z","shell.execute_reply":"2022-09-21T06:32:32.889121Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"2022-09-21 14:09:19 [INFO] start training: model_id=20220921-140743, n_fold=5, target_fold=[0], early_stopping=False\n2022-09-21 14:09:19 [INFO] fold-0 start\n2022-09-21 14:09:20 [INFO] model_lr: 0.002\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9864355261cc40aabb7845df0622abd0"}},"metadata":{}},{"name":"stdout","text":"2022-09-21 14:09:50 [INFO] start epoch-0: generation: 0 -> 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"2022-09-21 14:24:56 [INFO] save history (generation=1): train_loss: 0.72245, valid_loss: 0.70022, score: 0.70022\n2022-09-21 14:24:56 [INFO] save identification to local: models/20220921-140743/fold0.idf.json\n2022-09-21 14:24:58 [INFO] save identification to GCS: models/semantic-segmentation-3D/baseline/segmentation/Unet/20220921-140743/fold0.idf.json\n2022-09-21 14:24:58 [INFO] start epoch-1: generation: 1 -> 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"2022-09-21 14:41:52 [INFO] save history (generation=2): train_loss: 0.69680, valid_loss: 0.69499, score: 0.69499\n2022-09-21 14:41:52 [INFO] save identification to local: models/20220921-140743/fold0.idf.json\n2022-09-21 14:41:53 [INFO] save identification to GCS: models/semantic-segmentation-3D/baseline/segmentation/Unet/20220921-140743/fold0.idf.json\n2022-09-21 14:41:54 [INFO] start epoch-2: generation: 2 -> 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"2022-09-21 14:57:06 [INFO] save history (generation=3): train_loss: 0.69381, valid_loss: 0.69319, score: 0.69319\n2022-09-21 14:57:06 [INFO] save identification to local: models/20220921-140743/fold0.idf.json\n2022-09-21 14:57:07 [INFO] save identification to GCS: models/semantic-segmentation-3D/baseline/segmentation/Unet/20220921-140743/fold0.idf.json\n2022-09-21 14:57:07 [INFO] start epoch-3: generation: 3 -> 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"2022-09-21 15:12:28 [INFO] save history (generation=4): train_loss: 0.69318, valid_loss: 0.69316, score: 0.69316\n2022-09-21 15:12:28 [INFO] save identification to local: models/20220921-140743/fold0.idf.json\n2022-09-21 15:12:30 [INFO] save identification to GCS: models/semantic-segmentation-3D/baseline/segmentation/Unet/20220921-140743/fold0.idf.json\n2022-09-21 15:12:30 [INFO] start epoch-4: generation: 4 -> 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"2022-09-21 15:29:22 [INFO] save history (generation=5): train_loss: 0.69316, valid_loss: 0.69316, score: 0.69316\n2022-09-21 15:29:22 [INFO] save identification to local: models/20220921-140743/fold0.idf.json\n2022-09-21 15:29:24 [INFO] save identification to GCS: models/semantic-segmentation-3D/baseline/segmentation/Unet/20220921-140743/fold0.idf.json\n2022-09-21 15:29:24 [INFO] start epoch-5: generation: 5 -> 6\n2022-09-21 15:32:22 [INFO] min-loss-model: /kaggle/working/models/20220921-140743/fold-0/min-loss_epoch=4.ckpt\n2022-09-21 15:32:27 [INFO] save model to GCS: models/semantic-segmentation-3D/baseline/segmentation/Unet/20220921-140743/fold-0/min-loss_epoch=4.ckpt\n2022-09-21 15:32:27 [INFO] max-score-model: /kaggle/working/models/20220921-140743/fold-0/max-score_epoch=0.ckpt\n2022-09-21 15:32:32 [INFO] save model to GCS: models/semantic-segmentation-3D/baseline/segmentation/Unet/20220921-140743/fold-0/max-score_epoch=0.ckpt\n2022-09-21 15:32:32 [INFO] fold-0 end\n2022-09-21 15:32:32 [INFO] end training\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}